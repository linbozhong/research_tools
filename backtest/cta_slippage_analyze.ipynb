{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path, PurePath\n",
    "from typing import List\n",
    "from datetime import datetime, timedelta\n",
    "from vnpy.trader.utility import round_to\n",
    "\n",
    "from utility import get_output_path, get_output_folder, strip_digt, load_data\n",
    "\n",
    "future_basic_data = pd.read_csv('future_basic_data.csv', index_col=0)\n",
    "pricetick = future_basic_data['pricetick']\n",
    "pricetick.index = pricetick.index.map(lambda x: x.lower())\n",
    "\n",
    "ZH_TO_EN_DICT = {\n",
    "    '多': 'long',\n",
    "    '空': 'short',\n",
    "    '开': 'open',\n",
    "    '平昨': 'close_yesterday',\n",
    "    '平': 'close',\n",
    "    '平今': 'close_today'\n",
    "}\n",
    "\n",
    "\n",
    "def clean_vt_log(file_path: PurePath) -> List[dict]:\n",
    "    data_list = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        commodity_re = re.compile(r'(60m:)|(:)')\n",
    "        split_re = r'(?:,|\\n|\\s)\\s*'\n",
    "        for line in f:\n",
    "            if '[Pre-stop Order]' in line or '[Stop Order]' in line:\n",
    "                fields = re.split(split_re, line)\n",
    "                line_dict = {}\n",
    "                line_dict['datetime'] = f\"{fields[0]} {fields[1]}\"\n",
    "                line_dict['commodity'] = commodity_re.sub(r'', fields[4]).lower()\n",
    "                line_dict['order_type'] = f\"{fields[5]} {fields[6]}\".strip('[]')\n",
    "                line_dict['direction'] = fields[7].replace('Direction:', '')\n",
    "                line_dict['offset'] = fields[8].replace('Offset:', '')\n",
    "                line_dict['test_price'] = fields[9].replace('Price:', '')\n",
    "                line_dict['volume'] = fields[10].replace('Volume:', '')\n",
    "\n",
    "                data_list.append(line_dict)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def clean_folder_logs(folder: PurePath) -> pd.DataFrame:\n",
    "    file_list = list(folder.glob(f'*.log'))\n",
    "    \n",
    "    data_list = []\n",
    "    for file in file_list:\n",
    "        data_list.extend(clean_vt_log(file))\n",
    "        \n",
    "    df = pd.DataFrame(data_list)\n",
    "    df[['test_price', 'volume']] = df[['test_price', 'volume']].astype('float')\n",
    "    df['datetime'] = df['datetime'].map(pd.to_datetime)\n",
    "    df['pricetick'] = df['commodity'].map(pricetick)\n",
    "#     df.to_csv(get_output_path('test.csv', root_default='server_log'), encoding='utf-8-sig')\n",
    "    df['price'] = [round_to(*tuple) for tuple in list(zip(df['test_price'], df['pricetick']))]\n",
    "    df['dt_flag'] = df['datetime'].map(lambda dt: dt.replace(minute=0, second=0))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_trade_file(file_path: PurePath) -> pd.DataFrame:\n",
    "    trade_columns = [\n",
    "        'datetime', 'exchange', 'trade_id', 'order_id', 'symbol', 'direction',\n",
    "        'offset', 'price', 'volume'\n",
    "    ]\n",
    "    trade_df = pd.read_csv(file_path, header=None, names=trade_columns, parse_dates=[0])\n",
    "    trade_df.drop(['trade_id', 'order_id'], axis=1, inplace=True)\n",
    "    trade_df['commodity'] = trade_df['symbol'].map(lambda x: strip_digt(x).lower())\n",
    "#     trade_df['multiplier'] = trade_df['symbol'].map(add_multiplier)\n",
    "    trade_df.loc[trade_df.direction == '空', 'volume'] *= -1\n",
    "    trade_df['dt_flag'] = trade_df['datetime'].map(lambda dt: dt.replace(minute=0, second=0))\n",
    "    return trade_df\n",
    "\n",
    "\n",
    "def is_open(delta) -> int:\n",
    "    result = 1 if delta <= timedelta(seconds=5) else 0\n",
    "    return result\n",
    "\n",
    "\n",
    "def compare_slip_level(trade: pd.DataFrame, backtest: pd.DataFrame, filename: str) -> pd.DataFrame:\n",
    "    merge_df = pd.merge(trade, log_df, on=['dt_flag', 'commodity'], how='left')\n",
    "    merge_df['slip_level'] = (merge_df['price_y'] - merge_df['price_x']) * (merge_df['volume'] / np.abs(merge_df['volume'])) / merge_df['pricetick']\n",
    "    merge_df['direction'] = merge_df['direction'].map(ZH_TO_EN_DICT)\n",
    "    merge_df['offset'] = merge_df['offset'].map(ZH_TO_EN_DICT)\n",
    "    merge_df['is_open'] = (merge_df['datetime_x'] - merge_df['datetime_y']).map(is_open)\n",
    "    non_open_filter = merge_df['dt_flag'].map(lambda dt: dt.hour != 9 and dt.hour != 21)\n",
    "    merge_df.loc[non_open_filter, 'is_open'] = 0\n",
    "\n",
    "    open_list = []\n",
    "    use_open_list = []\n",
    "    slip_level_list = []\n",
    "    for idx, row in merge_df.iterrows():\n",
    "        if row['is_open']:\n",
    "            vt_symbol = f\"{row['symbol']}.{row['exchange']}\"\n",
    "            begin_dt = end_dt = row['dt_flag'].to_pydatetime()\n",
    "#             print(vt_symbol, begin_dt)\n",
    "            k_line = load_data(vt_symbol, '1h', begin_dt, end_dt)\n",
    "\n",
    "            open_price = k_line.iloc[0]['open']\n",
    "            open_list.append(open_price)\n",
    "\n",
    "            if row['direction'] == 'long' and open_price > row['test_price']:\n",
    "                use_open_list.append(1)\n",
    "                slip_level = (open_price - row['price_x']) / row['pricetick']\n",
    "            elif row['direction'] == 'short' and open_price < row['test_price']:\n",
    "                use_open_list.append(1)\n",
    "                slip_level = (row['price_x'] - open_price) / row['pricetick']\n",
    "            else:\n",
    "                use_open_list.append(0)\n",
    "                slip_level = row['slip_level']\n",
    "\n",
    "            slip_level_list.append(slip_level)\n",
    "        else:\n",
    "            open_list.append(0)\n",
    "            use_open_list.append(0)\n",
    "            slip_level_list.append(row['slip_level'])\n",
    "    merge_df['open'] = open_list\n",
    "    merge_df['use_open'] = use_open_list\n",
    "    merge_df['actual_slip'] = slip_level_list\n",
    "\n",
    "    merge_df.dropna(inplace=True)\n",
    "    merge_df.to_csv(get_output_path(filename, root_default='server_log'))\n",
    "    return merge_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 55\n",
    "filename = f\"compare_slip_entry_{window}.csv\"\n",
    "\n",
    "file_path = get_output_path(f\"trade_turtle_entry_{window}.csv\", root_default='server_log')\n",
    "trade_df = load_trade_file(file_path)\n",
    "trade_df.drop_duplicates(inplace=True)\n",
    "print(len(trade_df))\n",
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = get_output_folder(f\"turtle_entry_{window}\", root_default='server_log')\n",
    "log_df = clean_folder_logs(folder)\n",
    "keep_items = ['commodity', 'dt_flag', 'datetime', 'test_price', 'price', 'pricetick']\n",
    "log_df = log_df[keep_items]\n",
    "print(len(log_df))\n",
    "log_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compare_slip_level(trade_df, log_df, filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(trade, log_df, on=['dt_flag', 'commodity'], how='left')\n",
    "merge_df['slip_level'] = (merge_df['price_y'] - merge_df['price_x']) * (merge_df['volume'] / np.abs(merge_df['volume'])) / merge_df['pricetick']\n",
    "merge_df['direction'] = merge_df['direction'].map(ZH_TO_EN_DICT)\n",
    "merge_df['offset'] = merge_df['offset'].map(ZH_TO_EN_DICT)\n",
    "merge_df['is_open'] = (merge_df['datetime_x'] - merge_df['datetime_y']).map(is_open)\n",
    "non_open_filter = merge_df['dt_flag'].map(lambda dt: dt.hour != 9 and dt.hour != 21)\n",
    "merge_df.loc[non_open_filter, 'is_open'] = 0\n",
    "\n",
    "open_list = []\n",
    "use_open_list = []\n",
    "slip_level_list = []\n",
    "for idx, row in merge_df.iterrows():\n",
    "    if row['is_open']:\n",
    "        vt_symbol = f\"{row['symbol']}.{row['exchange']}\"\n",
    "        begin_dt = end_dt = row['dt_flag'].to_pydatetime()\n",
    "        k_line = load_data(vt_symbol, '1h', begin_dt, end_dt)\n",
    "        \n",
    "        open_price = k_line.iloc[0]['open']\n",
    "        open_list.append(open_price)\n",
    "\n",
    "        if row['direction'] == 'long' and open_price > row['test_price']:\n",
    "            use_open_list.append(1)\n",
    "            slip_level = (open_price - row['price_x']) / row['pricetick']\n",
    "        elif row['direction'] == 'short' and open_price < row['test_price']:\n",
    "            use_open_list.append(1)\n",
    "            slip_level = (row['price_x'] - open_price) / row['pricetick']\n",
    "        else:\n",
    "            use_open_list.append(0)\n",
    "            slip_level = row['slip_level']\n",
    "        \n",
    "        slip_level_list.append(slip_level)\n",
    "    else:\n",
    "        open_list.append(0)\n",
    "        use_open_list.append(0)\n",
    "        slip_level_list.append(row['slip_level'])\n",
    "merge_df['open'] = open_list\n",
    "merge_df['use_open'] = use_open_list\n",
    "merge_df['actual_slip'] = slip_level_list\n",
    "\n",
    "merge_df.dropna(inplace=True)\n",
    "merge_df.to_csv(get_output_path('slip_compare.csv', root_default='server_log'))\n",
    "merge_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
