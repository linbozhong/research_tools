{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('commission_fol.json', 'r') as f:\n",
    "    commission_multiple = json.load(f)\n",
    "    \n",
    "excluded_trades = set()\n",
    "size_dict = {\n",
    "    'IF': 300,\n",
    "    'IH': 300,\n",
    "    'IC': 200\n",
    "}\n",
    "\n",
    "def strip_digit(symbol: str):\n",
    "    res = \"\"\n",
    "    for char in symbol:\n",
    "        if not char.isdigit():\n",
    "            res += char\n",
    "        else:\n",
    "            break\n",
    "    return res\n",
    "\n",
    "def open_trade_file(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file, parse_dates=[0], encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file, parse_dates=[0], encoding='gb2312')\n",
    "    return df\n",
    "\n",
    "def calc_trade(df: pd.DataFrame, account_type: str):\n",
    "    df_sel = df[df['account_type'] == account_type]\n",
    "    df_sel = df_sel[~(df_sel['vt_orderid'].isin(excluded_trades))].copy()\n",
    "#     print(df_sel)\n",
    "    \n",
    "    df_sel['size'] = df_sel['symbol'].map(strip_digit).map(size_dict)\n",
    "    df_sel['turnover'] = df_sel['price'] * df_sel['volume'] * df_sel['size']\n",
    "    df_sel['com_multiple'] = df_sel['account_id'].map(commission_multiple)\n",
    "    df_sel['comission'] = df_sel['turnover'] * df_sel['com_multiple'] * (0.23 / 10000)\n",
    "    \n",
    "    df_sel_long = df_sel[df_sel['direction'] == \"多\"]\n",
    "    df_sel_short = df_sel[df_sel['direction'] == \"空\"]\n",
    "    \n",
    "    order_fee = len(df_sel)\n",
    "    \n",
    "    d = {}\n",
    "    d['date'] = df_sel.iloc[0]['date']\n",
    "    d['account'] = df_sel.iloc[0]['account_id']\n",
    "    d['comission'] = df_sel['comission'].sum() + order_fee\n",
    "    d['long_volume'] = df_sel_long['volume'].sum()\n",
    "    d['long_turnover'] = df_sel_long['turnover'].sum()\n",
    "    d['long_cost'] = sum(df_sel_long['price'] * df_sel_long['volume']) / d['long_volume']\n",
    "    d['short_volume'] = df_sel_short['volume'].sum()\n",
    "    d['short_turnover'] = df_sel_short['turnover'].sum()\n",
    "    d['short_cost'] = sum(df_sel_short['price'] * df_sel_short['volume']) / d['short_volume']\n",
    "    d['trade_pnl'] = d['short_turnover'] - d['long_turnover']\n",
    "    d['net_pnl'] = d['trade_pnl'] - d['comission']\n",
    "    d['all_volume'] = d['long_volume'] + d['short_volume']\n",
    "    \n",
    "#     print('手续费', d['account'], d['comission'])\n",
    "    df = pd.DataFrame([d])\n",
    "#     df.set_index('date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def stats_trade_by_date(file):\n",
    "    df = open_trade_file(file)\n",
    "    df[['account_id', 'tradeid']] = df[['account_id', 'tradeid']].astype('str')\n",
    "    \n",
    "    source_res = calc_trade(df, 'source')\n",
    "    target_res = calc_trade(df, 'target')\n",
    "    \n",
    "    df_res = pd.merge(source_res, target_res, how='outer', on='date', suffixes=('_source', '_target'))\n",
    "    df_res['net_pnl_diff'] = df_res['net_pnl_source'] - df_res['net_pnl_target']\n",
    "    df_res['trade_pnl_diff'] = df_res['trade_pnl_source'] - df_res['trade_pnl_target']\n",
    "    df_res['long_diff'] = df_res['long_cost_target'] - df_res['long_cost_source']\n",
    "    df_res['short_diff'] = df_res['short_cost_source'] - df_res['short_cost_target']\n",
    "    df_res['trade_diff'] = (df_res['long_diff'] + df_res['short_diff']) / 2\n",
    "    \n",
    "    display_cols = [\n",
    "                    'date', 'account_source', 'account_target',\n",
    "                    'all_volume_source', 'all_volume_target',\n",
    "#                     'trade_pnl_source', 'trade_pnl_target',\n",
    "#                     'trade_pnl_diff',\n",
    "                    'net_pnl_source', 'net_pnl_target',\n",
    "                    'net_pnl_diff', 'trade_diff'\n",
    "                   ]\n",
    "\n",
    "    en_to_zh = {\n",
    "        'date': '日期', 'account_source': '标准户', 'account_target': '跟单户',\n",
    "        'all_volume_source': '标准户笔数', 'all_volume_target': '跟单户笔数',\n",
    "#         'trade_pnl_source': '标准户交易盈亏', 'trade_pnl_target': '跟单户交易盈亏',\n",
    "#         'trade_pnl_diff': '交易盈亏差',\n",
    "        'net_pnl_source': '标准户净盈亏', 'net_pnl_target': '跟单户净盈亏',\n",
    "        'net_pnl_diff': '净盈亏差',\n",
    "        'trade_diff': '滑点差'\n",
    "    }\n",
    "    \n",
    "    df2 = df_res[display_cols].copy()\n",
    "    df2.rename(columns=en_to_zh, inplace=True)\n",
    "    return df2\n",
    "\n",
    "def load_exclude_trades(folder):\n",
    "    filter_folder = folder.joinpath('filter_traded')\n",
    "    if filter_folder.exists():\n",
    "        files = filter_folder.glob('*.csv')\n",
    "        all_dfs = []\n",
    "        for file in files:\n",
    "            fn = file.name\n",
    "            if not fn.startswith('trade'):\n",
    "                continue\n",
    "\n",
    "            df = open_trade_file(file)\n",
    "            all_dfs.append(df)\n",
    "\n",
    "        all_exclude_df = pd.concat(all_dfs, axis=0)\n",
    "        return all_exclude_df['vt_orderid'].to_list()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def stats_trade_by_folder(folder):\n",
    "    existed_records = []\n",
    "    pnl_df = None\n",
    "\n",
    "    pnl_fn = \"pnl_result.csv\"\n",
    "    pnl_file = folder.joinpath(pnl_fn)\n",
    "    if pnl_file.exists():\n",
    "        pnl_df = pd.read_csv(pnl_file, parse_dates=[0], encoding='utf-8')\n",
    "    #     print(pnl_df)\n",
    "        existed_records  = pnl_df['日期'].map(lambda dt: dt.strftime('%Y%m%d')).tolist()\n",
    "    #     print(existed_records)\n",
    "\n",
    "    files = folder.glob('*.csv')\n",
    "    all_dfs = []\n",
    "    for file in files:\n",
    "        fn = file.name\n",
    "        if not fn.startswith('trade'):\n",
    "            continue\n",
    "\n",
    "        trade_date = file.name.split('.')[0].split('_')[1]\n",
    "    #     print(file, type(file), trade_date) \n",
    "        if trade_date in existed_records:\n",
    "            print(f\"{trade_date}数据已存在\")\n",
    "            continue\n",
    "\n",
    "        file_df = stats_trade_by_date(file)\n",
    "        all_dfs.append(file_df)\n",
    "\n",
    "    if all_dfs:\n",
    "        if pnl_df is not None:\n",
    "            all_dfs.append(pnl_df)\n",
    "\n",
    "        new_pnl_df = pd.concat(all_dfs, join=\"inner\")\n",
    "        new_pnl_df.sort_values(by=\"日期\", inplace=True)\n",
    "#         new_pnl_df.to_csv(pnl_file, index=False)\n",
    "    else:\n",
    "        new_pnl_df = pnl_df\n",
    "\n",
    "    items_to_process = [\n",
    "        ('标准户笔数', '标准户累计笔数'),\n",
    "        ('跟单户笔数', '跟单户累计笔数'),\n",
    "        ('标准户净盈亏', '标准户累计净盈亏'),\n",
    "        ('跟单户净盈亏', '跟单户累计净盈亏'),\n",
    "        ('净盈亏差', '累计净盈亏差')\n",
    "    ]\n",
    "    for (item, item_cum) in items_to_process:\n",
    "        new_pnl_df[item_cum] = new_pnl_df[item].rolling(window=len(new_pnl_df), min_periods=1).sum()\n",
    "    new_pnl_df['平均滑点差'] = new_pnl_df['滑点差'].rolling(window=len(new_pnl_df), min_periods=1).mean()\n",
    "    \n",
    "    new_pnl_df.to_csv(pnl_file, index=False)\n",
    "    return new_pnl_df\n",
    "\n",
    "def stats_all(folders):\n",
    "    pnls = []\n",
    "    for folder in folders:\n",
    "        pnl_file = folder.joinpath(\"pnl_result.csv\")\n",
    "        if pnl_file.exists():\n",
    "            pnl_df = pd.read_csv(pnl_file, parse_dates=[0], encoding='utf-8')\n",
    "            pnls.append(pnl_df)\n",
    "            \n",
    "    all_pnl_file = Path(r'D:\\work\\all_pnl_result.csv')\n",
    "    all_pnl_df = pd.concat(pnls, join=\"inner\")\n",
    "    all_pnl_df.sort_values(by=\"日期\", inplace=True)\n",
    "    \n",
    "    int_items = [\n",
    "        '标准户净盈亏',\n",
    "        '跟单户净盈亏',\n",
    "        '净盈亏差',\n",
    "        '标准户累计净盈亏',\n",
    "        '跟单户累计净盈亏',\n",
    "        '累计净盈亏差'\n",
    "    ]\n",
    "    all_pnl_df[int_items] = all_pnl_df[int_items].astype('int')\n",
    "    \n",
    "    round_float_items = ['滑点差', '平均滑点差']\n",
    "    for item in round_float_items:\n",
    "        all_pnl_df[item] = all_pnl_df[item].map(lambda value: round(value, 2))\n",
    "\n",
    "    all_pnl_df.to_csv(all_pnl_file, index=False)\n",
    "    return all_pnl_df\n",
    "\n",
    "\n",
    "def merge_trades(trade_folder, to_merge_days):\n",
    "    fp_list = []\n",
    "    dfs = []\n",
    "    for file in trade_folder.glob(r'trade*.csv'):\n",
    "    #     print(file, type(file))\n",
    "        for day in to_merge_days:\n",
    "            if day in file.name:\n",
    "                fp_list.append(file)\n",
    "                dfs.append(open_trade_file(file))\n",
    "                file.rename(file.parent.joinpath(file.name + '.automerge'))\n",
    "\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    df.sort_values(by=\"dt\", ascending=False, inplace=True)\n",
    "\n",
    "    new_fp = trade_folder.joinpath(f\"trade_{to_merge_days[-1]}.csv\")\n",
    "    df.to_csv(new_fp, index=False)\n",
    "    print(\"合并完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder1 = Path(r'D:\\work\\rd_liu')\n",
    "excluded_trades.update(load_exclude_trades(folder1))\n",
    "print(excluded_trades)\n",
    "df = stats_trade_by_folder(folder1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder2 = Path(r'D:\\work\\rd_huang')\n",
    "excluded_trades.update(load_exclude_trades(folder2))\n",
    "print(excluded_trades)\n",
    "df = stats_trade_by_folder(folder2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_day = None\n",
    "# compare_day = datetime(2020, 7, 31)\n",
    "folders = [folder1, folder2]\n",
    "# folders = [folder1]\n",
    "\n",
    "all_pnl_df = stats_all(folders)\n",
    "\n",
    "if compare_day is None:\n",
    "    compare_day = datetime.today()\n",
    "    \n",
    "all_pnl_df[all_pnl_df['日期'] == pd.Timestamp(compare_day.date())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单文件测试\n",
    "file = Path(r'D:\\work\\rd_liu\\trade_20200804.csv')\n",
    "df = stats_trade_by_date(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并多日成交记录\n",
    "trade_folder = Path(r'D:\\work\\rd_huang')\n",
    "to_merge_days = ['20200811', '20200812']\n",
    "\n",
    "merge_trades(trade_folder, to_merge_days)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
